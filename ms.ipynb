{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "# 选取数据\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('/home/user02/code/数据/crossdocked_pocket10/index.pkl', 'rb') as f:\n",
    "    index = pickle.load(f)\n",
    "    index.reverse()\n",
    "\n",
    "index1 = []\n",
    "for i in range(len(index)):\n",
    "    if index[i][0] == None: continue\n",
    "\n",
    "    if '1B57_HUMAN_25_300_0' in index[i][0]:\n",
    "\n",
    "        # print(index[i][0])\n",
    "        index1.append(index[i])\n",
    "print(len(index1))\n",
    "\n",
    "# 加载配置\n",
    "from utils.misc import load_config\n",
    "\n",
    "config = load_config('/home/user02/CProMG_ms/configs/CPrMG-VQSLT.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义预处理类\n",
    "\n",
    "class FeaturizeProteinAtom(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.atomic_numbers = ms.Tensor([1, 6, 7, 8, 16, 34], ms.int64)    # H, C, N, O, S, Se\n",
    "        self.max_num_aa = 20\n",
    "\n",
    "\n",
    "    @property\n",
    "    def feature_dim(self):\n",
    "        return self.atomic_numbers.size + 1\n",
    "\n",
    "    def __call__(self, data):\n",
    "\n",
    "        element = data.protein_element.view(-1, 1) == self.atomic_numbers.view(1, -1) # (N_atoms, N_elements) onehot    \n",
    "        element = element.to(ms.int64)   \n",
    "        is_backbone = data.protein_is_backbone.view(-1, 1).long()\n",
    "        x = ops.cat([element, is_backbone], axis=-1)\n",
    "        data.protein_atom_feature = x\n",
    "        # del data.protein_molecule_name, data.protein_is_backbone, data.protein_atom_name, data.protein_atom_to_aa_type\n",
    "        return data\n",
    "    \n",
    "class FeaturizeProteinResidue(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.max_num_aa = 20\n",
    "\n",
    "    @property\n",
    "    def feature_dim(self):\n",
    "        return self.max_num_aa \n",
    "\n",
    "    def __call__(self, data):\n",
    "        # amino_acid = F.one_hot(data.residue_amino_acid.to(ms.int64), num_classes=self.max_num_aa)\n",
    "        amino_acid = ops.one_hot(data.residue_amino_acid.to(ms.int64), self.max_num_aa)\n",
    "        data.residue_feature = amino_acid\n",
    "\n",
    "        return data\n",
    "\n",
    "# 实例化\n",
    "protein_featurizer = FeaturizeProteinAtom()\n",
    "residue_featurizer = FeaturizeProteinResidue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "import os\n",
    "import pandas as pd\n",
    "from utils.protein_ligand import PDBProtein, parse_sdf_file\n",
    "from utils.data import add_prefix\n",
    "\n",
    "class KeyDict(dict):\n",
    "    def __getattr__(self, key):\n",
    "        try:\n",
    "            return self[key]\n",
    "        except KeyError:\n",
    "            raise AttributeError(key)\n",
    "        \n",
    "def pad_row(arr, max_len):\n",
    "    \n",
    "    arr = ms.Tensor(arr)\n",
    "    zero_arr = ops.zeros((max_len, arr.shape[1]))\n",
    "    zero_arr[:arr.shape[0], :arr.shape[1]] = arr\n",
    "    padded_arr = zero_arr\n",
    "    mask = ops.zeros((max_len, 1))\n",
    "    mask[:arr.shape[0], 0] = 1\n",
    "    return padded_arr, mask\n",
    "\n",
    "\n",
    "raw_path = './data/crossdocked'\n",
    "df = pd.read_csv('./data/dock_scores.csv')\n",
    "data_lis = []\n",
    "\n",
    "for i, (pocket_fn, ligand_fn, _, rmsd_str) in enumerate(index1):\n",
    "    pocket_dict = PDBProtein(os.path.join(raw_path, pocket_fn)).to_dict_atom()\n",
    "    residue_dict = PDBProtein(os.path.join(raw_path, pocket_fn)).to_dict_residue()\n",
    "    ligand_dict = parse_sdf_file(config,os.path.join(raw_path, ligand_fn))\n",
    "    data = add_prefix(pocket_dict, residue_dict, ligand_dict)\n",
    "    data = KeyDict(data)\n",
    "    try:\n",
    "        data['vina_score'] = float(df[df.loc[:,'4']==ligand_fn].loc[:,'5'].item())\n",
    "    except:\n",
    "        data['vina_score'] = float(0)\n",
    "\n",
    "    data.num_nodes = data.protein_element.size\n",
    "\n",
    "    protein_featurizer(data)\n",
    "    residue_featurizer(data)\n",
    "    new_data = {}\n",
    "    new_data['protein_atom_feature'], new_data['protein_atom_feature_mask'] = pad_row(data.protein_atom_feature, max_len=600)\n",
    "    new_data['residue_feature'], new_data['residue_feature_mask'] = pad_row(data.residue_feature, 100)\n",
    "    keys_to_add = ['ligand_smile', 'ligand_sas', 'ligand_logP', 'ligand_qed', 'ligand_tpsa', 'ligand_smiIndices_input', 'ligand_smiIndices_tgt', 'vina_score']\n",
    "    for key in keys_to_add:\n",
    "        new_data[key] = data[key]\n",
    "    # print(data)\n",
    "    # print(data.protein_element.view(-1, 1))\n",
    "    # break\n",
    "        \n",
    "    data_lis.append(new_data)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lis = [[dic[key]  for key in dic.keys()] for dic in data_lis]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['protein_atom_feature',\n",
       " 'protein_atom_feature_mask',\n",
       " 'residue_feature',\n",
       " 'residue_feature_mask',\n",
       " 'ligand_smile',\n",
       " 'ligand_sas',\n",
       " 'ligand_logP',\n",
       " 'ligand_qed',\n",
       " 'ligand_tpsa',\n",
       " 'ligand_smiIndices_input',\n",
       " 'ligand_smiIndices_tgt',\n",
       " 'vina_score']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['protein_atom_feature', 'protein_atom_feature_mask', 'residue_feature', 'residue_feature_mask', 'ligand_smile', 'ligand_sas', 'ligand_logP', 'ligand_qed', 'ligand_tpsa', 'ligand_smiIndices_input', 'ligand_smiIndices_tgt', 'vina_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinLigandDataset:\n",
    "    def __init__(self, data_lis):\n",
    "        self.data_lis = data_lis\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_lis)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        return self.data_lis[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.dataset import GeneratorDataset\n",
    "\n",
    "dataset = ProteinLigandDataset(data_lis)\n",
    "# for i in dataset:\n",
    "#     print(i)\n",
    "#     break\n",
    "ds = GeneratorDataset(dataset, \n",
    "                      ['protein_atom_feature', 'protein_atom_feature_mask', 'residue_feature', 'residue_feature_mask', 'ligand_smile', 'ligand_sas', 'ligand_logP', 'ligand_qed', 'ligand_tpsa', 'ligand_smiIndices_input', 'ligand_smiIndices_tgt', 'vina_score'], \n",
    "                      shuffle=False).batch(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ds.create_tuple_iterator():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义循环迭代\n",
    "def inf_iterator(iterable):\n",
    "    iterator = iterable.__iter__()\n",
    "    while True:\n",
    "        try:\n",
    "            yield iterator.__next__()\n",
    "        except StopIteration:\n",
    "            iterator = iterable.__iter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.nn import CrossEntropyLoss\n",
    "from mindspore.experimental.optim import Adam\n",
    "from mindspore.experimental.optim.lr_scheduler import ReduceLROnPlateau\n",
    "optimizer = Adam(\n",
    "            model.parameters(),\n",
    "            lr=config.train.optimizer.lr,\n",
    "            weight_decay=config.train.optimizer.weight_decay,\n",
    "            betas=(config.train.optimizer.beta1, config.train.optimizer.beta2, )\n",
    "            )\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            factor=config.train.scheduler.factor,\n",
    "            patience=config.train.scheduler.patience,\n",
    "            min_lr=config.train.scheduler.min_lr\n",
    "        )\n",
    "\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
